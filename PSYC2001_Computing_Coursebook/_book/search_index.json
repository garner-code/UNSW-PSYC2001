[["index.html", "Data Analysis Skills for Psychology in R Course Information 0.1 The purpose of this coursebook 0.2 Structure of the Coursebook 0.3 Bugs are important 0.4 Setting up R and RStudio", " Data Analysis Skills for Psychology in R Kelly G. Garner, Bart Cooley, Marios Panayi, Peter Lovibond 2025-10-17 Course Information 0.1 The purpose of this coursebook Welcome to the computing tutorials for PSYC2001. This coursebook has been designed to support your learning of statistics through hands-on practice with R. It accompanies the tutorial folders available on Moodle, and will guide you step-by-step through the data analysis components of the course. The focus is not just on memorising, but on learning how to think about data, ask good questions, and use R as a tool to answer them. 0.2 Structure of the Coursebook Each chapter introduces a key concept in statistics. You will see worked examples with code that runs in R. These examples show you how to apply data analysis statistical techniques step by step. Throughout the chapters, you will find exercises to help you complete code in your own scripts. Completing the code in your own scripts is important, because you will need these coding skills to complete your assignment for the course, and beyond! Throughout this course book there will be questions that encourage you to think about about or apply what you’ve learned in new situation. 0.3 Bugs are important Learning to code involves making lots of errors. When a piece of code doesn’t work, it’s because you have a ‘bug’ in your code. This can feel disheartening at first, because we often think that bugs are a sign of failure. But bugs are actually an important part of learning to code. They help you to understand how the code works, and they help you to learn how to debug your code. So, don’t be afraid of bugs! Embrace them as part of the learning process. In fact, once you’ve been coding long enough, you’ll become deeply suspicious when you don’t find bugs. 0.4 Setting up R and RStudio All of the UNSW School of Psychology computers have R and R Studio installed. However, we can only guarantee that the computers in the Level 2 psychology labs have the right set-up. Both R and RStudio are freely available so you may wish to install them on your own machine. There is a useful guide to installing them both here that you can use. Note that the PSYC2001 staff are unable to help you if you have specific technical issues setting up R and RStudio on your own machine. But the tutors can support you using R and RStudio on the School of Psychology computers in the computer labs. If you are having specific technical issues setting this up on your own machine, then you should submit an issue to UNSW IT Services. "],["introduction-to-r.html", "Chapter 1 Introduction to R 1.1 R and R Studio 1.2 Getting started 1.3 Getting to know R Studio 1.4 Scripts 1.5 Functions and arguments 1.6 Base R and packages 1.7 Installing and loading packages 1.8 Objects 1.9 Datatypes 1.10 Looking after the environment 1.11 The power of scripts 1.12 You are Free!", " Chapter 1 Introduction to R Credit: This chapter heavily borrows from the work of Emily Nordmann at the University of Glasgow. Thanks, Emily! https://psyteachr.github.io/ads-v3/01-intro.html To perform data analysis in Psychology, one needs some powerful software to help you get data into shape, and to apply all the fancy statistical tests that you will learn about in this course. In this course, we will be using the programming language R and the software R Studio to do this. 1.1 R and R Studio For this course, you need two different bits of software, R and RStudio. R is a programming language that you will write code in and R Studio is an Integrated Development Environment (IDE) which makes working with R easier. Think of it as knowing English and using a plain text editor like NotePad to write a book versus using a word processor like Microsoft Word. You could do it, but it wouldn’t look as good and it would be much harder without things like spell-checking and formatting. In a similar way, you can use R without R Studio but we wouldn’t recommend it. The key thing to remember is that although you will do all of your work using R Studio for this course, you are actually using two pieces of software which means that from time-to-time, both of them may have separate updates. Figure 1.1: This is what using R without RStudio looks like. Noone wants that. 1.2 Getting started You should have downloaded the files you need for this week’s computing lab tutorial from the course Moodle. Unzip the folder you have downloaded, move the folder somewhere sensible, e.g. from ‘Downloads’ to ‘Documents’. Ask your tutor if you are unsure about any of those steps. Once the folder is unzipped and moved, open it up to take a peek at the contents inside. You should see something like the following - Figure 1.2: Every lab folder will contain the files you need for the session, and sometimes folders with extra things in them Each week you will get a folder that looks somewhat like this. Each week, your first job is to download the folder, unzip it and move it to your sensible location, and then double click on the file that ends in ‘.Rproj’. This will open RStudio. Why should I open RStudio by clicking on the ‘.Rproj’ file? Indeed, this may seem like a strange request. .Rproj files automatically tells R where your files are located. This is called ‘setting the working directory’. What this means is that you won’t have to manually tell R where on the computer your needed files live (why will become clearer next week). This also means you get to save a lot of typing in future computing lab tutorials. 1.3 Getting to know R Studio R Studio has a console that you can try out code in (appearing as the bottom left window in Figure 1.3. If you have opened a script, then there is a script editor (top left, more on scripts shortly below). There is also a window showing functions and objects you have created in the “Environment” tab (top right window in the figure), and a window that shows files, plots, packages, and help documentation (bottom right). Figure 1.3: The RStudio interface: ah, that’s better! 1.3.1 Activity - using the console First let’s get used to the console where you can try out code. You can think of the console as a very fancy calculator. You can do some impressive calculations, but like a calculator, once you close it down, everything you did is lost. Click on the Console (anywhere), and type the following: 2 + 2 Then press enter. You should see that R has calculated the answer for you. You can try other calculations, for example (you should also do this one): (5 + 4 + 3) / 3 Important! If you are ever unsure about what a piece of code is doing, you should try running it (or bits of it) in the console, to see what answers each bit of code gives you. This is a great way to learn what code does and to debug your own code when it doesn’t work. 1.4 Scripts The console is great for small calculations and testing code, but it isn’t very good for doing analyses that you want to keep. For this, we use scripts. A script is simply a text file that contains code. You know you have an R script when the filename ends in ‘.R’. You can write code in a script and then run it in the console. This means that you can save your code and come back to it later. It also means that anyone, anywhere else in the world can reproduce your analysis by running your script. This is a key part of open science and reproducible research. 1.4.1 Activity - Getting to know scripts Open the script your-first-script.R in R Studio. You can do this by clicking on the file in the Files tab (bottom right window) or by using File &gt; Open File… from the top menu. You can see at the top of the script there are some comments. Comments are lines of text that start with a # symbol. R ignores these lines when it runs the code, but they are useful for you to write notes to yourself about what the code is doing. You should always include comments in your code to explain what it is doing. This helps you remember what you did when you come back to it later, and it helps others understand your code if you share it with them. Figure 1.4: Scripts can run your code as many times as you please. Try typing 2 + 2 into the script, below the comment that says # Type 2 + 2 here. Now try running that bit of code in the script. You can do this by highlighting the line(s) of code you want to run and then clicking the ‘Run’ button at the top of the script window (see Figure 1: Run button). You should see that the answer appears in the console. Figure 1.5: Highlight your code and then run it. Important life hack! Another way to do this is to highlight the code you want to run and then press Ctrl + Enter (or Cmd + Enter on a Mac). Try this now. You should now see the result in the console. Figure 1.6: We all want results. Remember to save your script regularly by clicking the save icon (or using Ctrl + S or Cmd + S on a Mac). Save it, save it now! 1.5 Functions and arguments Functions in R allow you to perform tasks that would take a long time to write out by hand, by only using one word! Think of them as nifty tools that will save you lots of typing, again and again. A function normally takes a number of arguments. You can look up all the arguments that a function takes by using the help documentation. You get help by using the format ?function. Before, we calculated (5 + 4 + 3) / 3 in the console. You may have noticed that we add three numbers and then divide by the total number of numbers we have. You may have also noticed that this is the formula for calculating the mean (or average) of a set of numbers. Often in Psychology, we want to calculate the mean when we have many more than three numbers. This is where functions come in handy. Let’s look at the function mean(). 1.5.1 Activity - using a function Look up the help documentation for mean() by typing ?mean in the console. You will see that there is a Description of the function, a guide to it’s Usage, and the Arguments you need to make the function work. In the Usage section, we see that mean() takes the following form: ## Default S3 method: mean(x, trim = 0, na.rm = FALSE, ...) In the Arguments section, there are explanations for each of the arguments. x is the set of numbers that we want to calculate the mean for. Do not worry about trim and na.rm. For now, they can remain as mythical arguments in the interest of simplicity. Let’s use the mean function. Highlight the following line of code in your script and run it: # run the below line of code to see what answer you get mean(x=c(5, 4, 3)) The output in the console should match the answer you got when you calculated (5 + 4 + 3) / 3 by hand. This is but a simple example, but I am sure you can imagine the power of functions when you have many more numbers to work with. You’ll see in the code above that we have put the numbers together in some brackets preceded by the letter c c(). This is another function that combines the numbers into something called a vector. You can think of a vector as a list of items of the same type (e.g., all numbers, or all words). We will learn more about vectors later in this course. Getting help on help It can be difficult to understand help documentation when you are first learning R. Know that you will not be the first. Many cries for help have been posted on stackoverflow.com. You can look there. Also, asking AI like ChatGPT can be useful. For example, you could ask “What does the mean() function in R do?” and it will give you a plain English explanation. However, be careful as AI can sometimes give incorrect information. Always double-check with the official help documentation or other reliable sources. And always always always triple check any code you get AI to help you write. 1.5.2 Argument names In the above example, we wrote out the argument name when using the mean (i.e., x), however, this is not strictly necessary. The following two lines of code would both produce the same result: mean(x=c(5, 4, 3)) mean(c(5, 4, 3)) Importantly, if you do not write out the argument names, R will use the default order of arguments, so, health warning, make sure you check the order when there is more than 1 argument! If you write out the argument names then you can write the arguments in whatever order you like: mean(trim=0, x=c(5, 4, 3), na.rm=FALSE) When you are first learning R, you may find it useful to write out the argument names as it can help you remember and understand what each part of the function is doing. However, as your skills progress you may find it quicker to omit the argument names and you will also see examples of code online that do not use argument names so it is important to be able to understand which argument each argument is referring to (or look up the help documentation to check). In this course, we will always write out the argument names the first time we use each function, however, in subsequent uses they may be omitted. 1.6 Base R and packages When you install R you will have access to a range of functions including options for data wrangling and statistical analysis. The functions that are included in the default installation are typically referred to as Base R and there is a useful cheat sheet that shows many Base R functions here. However, the power of R is that it is extendable and open source - put simply, if a function doesn’t exist or doesn’t work very well, anyone can create a new package that contains data and code to allow you to perform new tasks. You may find it useful to think of Base R as the default apps that come on your phone and packages as additional apps that you need to download separately. 1.7 Installing and loading packages Info: The UNSW psychology computers will already have all of the packages you need for this course so you only need to install packages if you are using your own machine. 1.7.1 Activity: Install the tidyverse In order to use a package, you must first install it. The following code installs the package tidyverse, a package we will use very frequently in this course. If you are interested in learning more about tidyverse and how incredibly useful it is in R, consider going through some of the chapters and exercises in R for Data Science. It’s also a great reference whenever you need help using functions from the tidyverse. If you want to learn more coding skills in R, we highly recommend working your way through this book. If you are working on your own computer, use the below code to install the tidyverse. You can either copy this command into the console, or into your script for highlighting and running Do not do this if you are working on a University machine. install.packages(&quot;tidyverse&quot;) You only need to install a package once, however, each time you start R you need to load the packages you want to use, in a similar way that you need to install an app on your phone once, but you need to open it every time you want to use it. To load packages we use the function library(). Typically you would start any analysis script by loading all of the packages you need, but we will come back to that in the later labs. 1.7.2 Activity: Load the tidyverse Run the below code in the console to load the tidyverse. You can do this regardless of whether you are using your own computer or a University machine. library(tidyverse) You will get what looks like an error message - it’s not. It’s just R telling you what it’s done. Now that we’ve loaded the tidyverse package we can use any of the functions it contains but remember, you need to run the library() function every time you start R. 1.8 Objects A large part of your coding for data analysis will involve creating and manipulating objects. Objects contain stuff. That stuff can be numbers, words, or the result of operations and analyses.You assign content to an object using &lt;-. 1.8.1 Activity: Create some objects Copy and paste the following code into the console, change the code so that it uses your own name and age and run it. You should see that name, age, today, new_year, and data appear in the environment pane. name &lt;- &quot;emily&quot; age &lt;- 15 + 18 today &lt;-Sys.Date() new_year &lt;- as.Date(&quot;2020-01-01&quot;) data &lt;- rnorm(n = 10, mean = 15, sd = 3) Figure 1.7: Objects in the environment Note that in these examples, name,age, and new_year would always contain the values emily, 33, and the date of New Year’s Day 2020, however, today will draw the date from the operating system. data has been created by randomly drawing a set of 10 values from a normal distribution with a mean of 15 and a standard deviation of 3. See ?rnorm for more information on how this function works. Warning: You may also see objects referred to as ‘variables’. There is a difference between the two in programming terms, however, they are used synonymously very frequently. As a side note, if you ever have to teach programming and statistics, don’t use your age as an example because everytime you have to update your teaching materials you get a reminder of the fragility of existence and your advancing age. Importantly, objects can be involved in calculations and can interact with each other. For example, copy and paste this code into your script and run it. Check your answer matches what you see below. age + 10 ## [1] 43 Finally, and importantly, you can store the result of these operations in a new object: decade &lt;- age + 10 Tip: You may find it helpful to read &lt;- as contains, e.g., name contains the text emily. 1.9 Datatypes You will constantly be creating objects throughout this course and you will learn more about them and how they behave as we go along. For now it is enough to understand that they are a way of saving values, that these values can be numbers, text, or the result of operations, and that they can be used in further operations to create new variables. For now, we can have a look at the datatypes of our objects using the function typeof. #These are both doubles (i.e numbers!) typeof(age) ## [1] &quot;double&quot; typeof(new_year) ## [1] &quot;double&quot; #This is a chr (i.e contains letters!) typeof(name) ## [1] &quot;character&quot; Info: There are 5 main datatypes: double, integer, complex, logical and character. For historic reasons, double is also called numeric. We will learn about using these datatypes (as well as some of the others) throughout this course, so don’t fret if you don’t understand it yet! 1.10 Looking after the environment If you’ve been writing a lot of code you may find that the environment pane (or workspace) has become cluttered with many objects. This can make it difficult to figure out which object you need and therefore you run the risk of using the wrong data. If you’re working on a new dataset, or if you’ve tried lots of different code before getting the final version, it is good practice to remember to clear the environment to avoid using the wrong object. You can do this in several ways. To remove individual objects, you can type rm(object_name) in the console. Complete the code in your script to remove the object data that we created earlier. To clear all objects from the environment run rm(list = ls()) in the console. To clear all objects from the environment you can also click the broom icon in the environment pane. Do it, do it now! Figure 1.8: Clearing the workspace 1.11 The power of scripts Now that you have cleared your Environment, you can learn the true power of scripts. They allow you to recreate your entire analysis from scratch, just by running the script. 1.11.1 Final Activity: Run the script The last activity for the day…highlight all the code in your script and run it. You should see all of the objects you created earlier reappear in the environment pane. 1.12 You are Free! Congratulations you have survived the first coding lab for this course. We look forward to seeing you next week for more coding fun. Figure 1.9: We know how you really feel "],["data-wrangling-and-visualisation.html", "Chapter 2 Data wrangling and visualisation 2.1 Checking installation and loading packages 2.2 What do packages do? 2.3 What do these packages do? 2.4 Organisation and CSV files 2.5 Importing your Data in R 2.6 Having a look at our data 2.7 Checking the quality of our data 2.8 Cleaning the data 2.9 Introducing Piping 2.10 Exporting Data 2.11 Data visualization using ggplot2 2.12 You are Free!", " Chapter 2 Data wrangling and visualisation Data analysis in Psychology and any other discipline is 90% data wrangling and 10% actual analysis. This week we will start to understand how to manipulate and visualise data using R. As usual, download the zipped lab folder from the Moodle page for this week and unzip it somewhere sensible on your computer. Double click the .Rproj file to open RStudio, and open the.R script file to get started. 2.1 Checking installation and loading packages Before we can begin any script we first need to make sure that the required packages are installed in our version of RStudio. Next, we can load the required packages to be used in the script, using the library() function. Copy and paste the code block below into your script in RStudio and try running it. R Coders always start their scripts by loading all the packages need to run all the code contained within the script. 2.1.1 Activity: Load your packages # Check if packages are installed, if not install. if(!require(here)) install.packages(&#39;here&#39;) #checks if a package is installed and installs it if required. if(!require(tidyverse)) install.packages(&#39;tidyverse&#39;) library(here) #loads in the specified package library(tidyverse) Note that in the code above, we’ve added a fancy if statement to check if the packages are installed. If they are not installed, it will install them for you. This is a good practice to ensure that your code runs smoothly on any computer without needing to manually install packages. Particularly if you are using the computers in the School of Psychology (UNSW), where we have already installed the packages you need (and we ask you not to install any more!). 2.2 What do packages do? You should be able to see that we have installed and loaded 2 different packages. Let’s first go over the basics of what a package is. In its simplest terms, a package is a toolbox that someone has created for us in R that makes our life easier. These packages build on the basic code that comes with the R programming language (what RStudio uses to run), called base R. Figure 2.1: The equivalent of loading an R package 2.3 What do these packages do? It is always a good idea to check the documentation for a package before you use it. We can do this by using the help syntax, which is the ?. The package we are trying to get help with is called here. 2.3.1 Activity: find out about packages Copy and paste the below line of code to find out more about the here package. This will open a help page that tells us the purpose of the package and how it works. ?here #? loads the documentation for a specified package. Handy hint: If you find the help page too overwhelming, try scrolling to the bottom and looking for the ‘Examples’ section. This will show you some simple code that uses the package. 2.4 Organisation and CSV files You should notice that the zipped folder you downloaded contains a few extra files and folders, compared to last lab. Generally, the file and folder structure will follow what you have here for the remaining labs. Here is a quick guide to what is there: An R Project file called ‘2_Data_wrangling_and_visualization.Rproj’ Use this to open RStudio. A script called ‘data_wrangling_and_visualization.R’. A text file called README.txt’, which contains information about the data. It is exceptionally good practice to make sure that your projects contain a README file that explains what the data is about. Hint: always read the README file. A folder called Data, containing a .csv file called ‘PSYC2001_social-media-data.csv’ A folder called Output, which is where all your output will go. These are the key ingredients needed to organise all projects in R. Figure 2.2: Project Organisation You will notice that the data for today, called PSYC2001_social-media-data.csv, is a csv file (short for a Comma Separated Value file). Read the README.txt file to learn more about the data, if you haven’t already. And if you haven’t already, why not? Always read the README file. csv files are a common and handy way to store data, because they can be read by heaps of different programs, like Excel, Google Sheets, and R. They are simple text files where each line represents a row of data, and the values in each row are separated by commas. Try double clicking on the csv file now to see what happens. You’ll see that Excel offers to open it for you. Click ok to open the file in Excel and take a look at how the data looks. Then say ‘that’s very kind of you Excel, but we are more powerful than you. We R.’ Figure 2.3: Social Media Data in Excel 2.5 Importing your Data in R We are now going to load our first dataset into R. To do this we will need to import the dataset using a function capable of importing csv files. 2.5.1 Activity: Import the data We will be using two different functions to achieve this. The read.csv() function is used to import our csv dataset and it comes from the utils package which is part of base R. But the read.csv() function needs to know where the file lives on the computer. To do this, we use the here() function from the here package. This function tells R the location of the project we are working from, to make locating the data easier. Let’s first confirm that here() knows our current location on this PC (called the ‘Working Directory’), by typing the following code into the console and hitting enter: here() This should return the file path to the folder where the .Rproj file is located. Because here can return where the folder lives (i.e. the file path), we can use this to easily find where our file is located and read it in. Thanks, here! You will see in your script that we’ve started this line of code for you. Copy and paste what is missing into your script and run it (or type it yourself, if you are seeking digital liberty). social_media &lt;- read.csv(file = here(&quot;Data&quot;,&quot;PSYC2001_social-media-data.csv&quot;)) #reads in csv files If you are still unsure what we mean by ‘file path’ then please google it, google it now. Now that we have read in our data, we have saved our data to an object called social_media. You can see this in the Environment tab in the top right section of your screen. Importantly, this particular object is a dataframe. A dataframe is a special type of object in R that is used to store data tables. It is similar to an Excel spreadsheet, or a data frame in Python’s pandas library. Dataframes are very useful for data analysis because they allow us to easily manipulate and analyze data. Warning: If you have an error, that’s all part of coding! But do make sure you ask your tutor for help :) 2.6 Having a look at our data Our data should now be imported into R! Recall from the README.txt file (you definitely should have read this by now) that this dataset was collected as part of an experiment investigating social media use in young Australian adults. Sixty young adults answered questions about their social media usage as well as their political attitudes. Data about their social media usage (e.g., likes) was collected while they used their preferred platforms under various conditions. The variables in the data are: id – a unique identifier (S1–S60) age – age in years time_on_social – average hours/day on social media (self-report diary) urban – urban (1) or rural (2) area (based on postcode density) -good_mood_likes – likes/10 min during a good mood (from platform + diary) bad_mood_likes – as above, but during bad mood followers – average number of followers across platforms The next 3 columns are political attitude subscales: informed – how politically informed they feel (e.g., read news daily) campaign – how much they engage in campaign-related discussion activism – involvement in activism (e.g., protests, petitions) We should now check that we have imported into Rstudio matches this description (and what we saw when we opened it in excel). There are a couple of ways to do this. 2.6.1 Activity: View the data. Always, always, view the data. It is incredibly important to have a look at the data you are analysing. This will quickly tell you if what you are planning to do is sensible, or if things are likely to go horribly wrong. The main thing to remember when running analysis is: garbage in, garbage out. If your data is rubbish, your results will be rubbish. So always check your data first. The first way is to manually click through to the dataset. You can do this by: Clicking on Environment in the top right section of your screen. Clicking on social_media. You should see a new tab pop up with the data in a table-like format (this is called a dataframe). Make sure that this new tab looks similar to what you saw when you opened Excel file. Figure 2.4: Navigating to dataset We can also do this programmatically using the code below. We’re taking you through some different ways of viewing data. Type the below into the console and run it. # Method 1 - Type in the name of the object social_media This will print the entire dataset to the console. This is not ideal for large datasets, but it works ok-ish for small ones like this. Now adjust the next bit of code in your script so that it exactly matches what you see below, and run it. You can also see from the comments how the data will appear. # Method 2 - Use the View function View(social_media) #view automatically displays the dataset in a tab. Sometimes, you only want to get a sense of what the data looks like, without printing the whole thing to the console or opening a new tab. The next two methods do just that. Copy and paste both of the below lines of code into your script and run them. # Method 3 - Use the head function head(social_media) #head displays the first 6 rows of each variable. ## id age time_on_social urban good_mood_likes bad_mood_likes followers polit_informed ## 1 S1 15.2 3.06 1 22.8 46.5 173.3 2.3 ## 2 S2 16.0 2.18 1 46.0 48.3 144.3 1.6 ## 3 S3 16.8 1.92 1 50.8 46.1 76.5 1.9 ## 4 S4 15.6 2.61 1 29.9 29.2 171.7 1.6 ## 5 S5 17.1 3.24 1 37.1 52.4 109.5 2.0 ## 6 S6 15.7 2.44 1 26.9 20.2 157.5 2.4 ## polit_campaign polit_activism ## 1 3.2 3.6 ## 2 2.2 2.6 ## 3 2.7 3.0 ## 4 2.3 2.6 ## 5 2.9 3.3 ## 6 3.4 3.9 # Method 4 - Use the str function str(social_media) #displays an overall summary of the object and variable structure. ## &#39;data.frame&#39;: 60 obs. of 10 variables: ## $ id : chr &quot;S1&quot; &quot;S2&quot; &quot;S3&quot; &quot;S4&quot; ... ## $ age : num 15.2 16 16.8 15.6 17.1 15.7 19.7 18.6 19.6 15.5 ... ## $ time_on_social : num 3.06 2.18 1.92 2.61 3.24 2.44 1.46 1.52 1.92 2.1 ... ## $ urban : int 1 1 1 1 1 1 1 1 1 1 ... ## $ good_mood_likes: num 22.8 46 50.8 29.9 37.1 26.9 14.8 26 6.5 45.7 ... ## $ bad_mood_likes : num 46.5 48.3 46.1 29.2 52.4 20.2 35.1 35.8 12.2 32.8 ... ## $ followers : num 173.3 144.3 76.5 171.7 109.5 ... ## $ polit_informed : num 2.3 1.6 1.9 1.6 2 2.4 1.7 1.6 1.5 2.2 ... ## $ polit_campaign : num 3.2 2.2 2.7 2.3 2.9 3.4 2.4 2.2 2.1 3.1 ... ## $ polit_activism : num 3.6 2.6 3 2.6 3.3 3.9 2.7 2.6 2.4 3.5 ... You should now have a good idea of what PSYC2001_social-media.csv looks like in RStudio. You should also be able to see that its a lot like what we saw in excel. You will also notice that the last function, str(), displays a summary of the object. This includes: The object type (a dataframe) The number of observations/rows (60) The number of variables/columns (10) The datatype: chr for id, and num for all other variables Question: Please discuss with your deskmate and tutor what you think chr and num mean. Figure 2.5: You thinking 2.7 Checking the quality of our data Once we have imported our dataset into R, it’s important to check the quality of the data. One simple way to do this is by using the summary() function. 2.7.1 Activity: Summarise the data Copy and paste the below line of code into your script and run it. summary(social_media) #summary provides a quick overview of the data in each variable. ## id age time_on_social urban good_mood_likes ## Length:60 Min. :13.90 Min. :-999.000 Min. :1.0 Min. : 6.50 ## Class :character 1st Qu.:15.70 1st Qu.: 1.920 1st Qu.:1.0 1st Qu.:31.60 ## Mode :character Median :16.50 Median : 2.365 Median :1.5 Median :45.90 ## Mean :16.87 Mean : -30.845 Mean :1.5 Mean :43.04 ## 3rd Qu.:17.43 3rd Qu.: 3.042 3rd Qu.:2.0 3rd Qu.:53.40 ## Max. :23.00 Max. : 4.320 Max. :2.0 Max. :89.20 ## bad_mood_likes followers polit_informed polit_campaign polit_activism ## Min. :12.20 Min. : 61.40 Min. :0.600 Min. :0.800 Min. :0.900 ## 1st Qu.:39.08 1st Qu.: 76.47 1st Qu.:1.500 1st Qu.:2.100 1st Qu.:2.400 ## Median :49.30 Median :116.30 Median :1.800 Median :2.550 Median :2.900 ## Mean :49.84 Mean :124.76 Mean :1.858 Mean :2.602 Mean :2.977 ## 3rd Qu.:58.75 3rd Qu.:153.75 3rd Qu.:2.200 3rd Qu.:3.100 3rd Qu.:3.500 ## Max. :91.20 Max. :336.50 Max. :3.400 Max. :4.800 Max. :5.500 Question: Do you notice anything unusual in the output of this data ? Discuss with your neighbour and tutor. Hint: Take a closer look at the time_on_social variable. 2.8 Cleaning the data It should now be clear that this data is unusual because it has a minimum value of -999 in the time_on_social variable which is measured in hours (we can’t have negative time !). Figure 2.6: Negative time would be back to the future! A good question to ask now is - why are these values in the dataset? Sometimes when collecting data, we can’t get a response from every participant. Instead of leaving a blank, researchers will sometimes put in a placeholder value like -999 to show that the data is missing. These aren’t real numbers; they just mean the data wasn’t recorded. But -999 isn’t the standard way to show missing data in R. R uses NA to represent missing values, and that’s important because most R functions know how to handle NA properly but they don’t know to ignore -999. 2.8.1 Activity: Find and replace -999 values Lets first have a look at how many -999 values are present in the data. We can do this by using the filter() function from the tidyverse package which is used to keep (or remove) rows based on certain conditions. social_media_filtered &lt;- filter(social_media, time_on_social == -999) #keep all rows where `time_on_social` is equal to -999 View(social_media_filtered) #view the filtered dataframe Handily, we can then use the count() function from the tidyverse package to sum the number of rows in the resulting dataframe. count(social_media_filtered) #count the number of rows in the filtered dataframe) ## n ## 1 2 2.9 Introducing Piping A short aside to introduce a very special operation called a ‘pipe’ or %&gt;%. This operation is part of the tidyverse package and allows you to pass the result from one function to the next seamlessly in a sort of assembly-line like fashion. Throughout the rest of the course we will be using ‘piping’ as it is easier to follow and code. For instance, lets repeat what we just did above but with pipes instead. 2.9.1 Activity: Pipe with pipes Copy and paste the below code into your script and run it. social_media %&gt;% #pass the values from social_media to the filter function filter(time_on_social == -999) %&gt;% #keep all rows that are equal to -999 and pass the result to count count() #count the number of remaining columns ## n ## 1 2 The answer should be satifsyingly the same as before. When coding, it is often a good idea to check you get the same answer by doing things in different ways. Then you know your code is doing the right thing and you can sleep well at night. Info: Piping is not friends with every function. Some functions will not accept inputs from pipes (no matter how nice they are !). This will become clearer as we code throughout this course. Now lets use a piping method to clean this data up by replacing -999 values with more R readable NA values. NA stands for ‘Not Available’ and is the standard way to represent missing data in R. We can do this using the mutate() and na_if() functions from the tidyverse package. The mutate() function is used to alter or make new columns in a dataframe based on the conditions we specify and na_if() is used to replace given values with NA in a dataframe. Copy and paste the below code into your script and run it. social_media_NA &lt;- social_media %&gt;% mutate(time_on_social = na_if(time_on_social,-999)) #mutate alters columns and rows. na_if replaces -999 with NA Now, very importantly, lets check that this worked by using the summary() function again. Re-use the summary() function in your code below the relevant comment. The one that says: ## Now run the summary() function again 2.10 Exporting Data It would be a good idea to save this dataset for future tutorials, so that we don’t have to replace -999 values with NA values every single time. We can do this with the write.csv() function from baseR. This function takes a dataframe in R and saves it as a .csv file on your computer. Later, we can simply read that csv back into R, and it will already be cleaned. 2.10.1 Activity: Save the cleaned data Copy and paste this code into your script and run it. Then open the Output folder to check that it worked. You can do this by clicking on the folder in the Files tab in the bottom right section of RStudio. write.csv(social_media_NA, here(&quot;Output&quot;,&quot;PSYC2001_social-media-data-cleaned.csv&quot;)) #creates a csv file from the dataframe social_media_NA 2.11 Data visualization using ggplot2 Visualizing data is a crucial step in data analysis. You should never run a statistical analysis without first visualising your data. It helps us understand the distribution of our data, identify patterns, and communicate our findings effectively. It also helps us identify whether the data is suitable for the analysis we want to perform, or whether some weird values remain that could influence the result of our statistical tests, and even worse, our interpretations! So, let’s look at some data! We’re going to start by visualising the time_on_social variable. To do this we will need to use the ggplot() function. This is the main function from the ggplot2 package which handily, comes for free with the tidyverse package. ggplot() provides the canvas of the graph you want to make. To make the basic canvas ggplot() requires two things: The data that you want it to plot. The variables to go on the x and y axes. Importantly, ggplot() only provides the canvas. It does not draw anything by itself. You have to add layers to the canvas created by ggplot() by using other functions that can create bars, points or lines ! 2.11.1 Activity: Create a boxplot in ggplot() First, let’s test what happens when we use ggplot() by itself. Complete the code in your script so that it matches the code block below and run it. social_media_NA %&gt;% ggplot(aes(y = time_on_social)) #ggplot uses aesthetic (aes()) to understand what # should be on the x and y axis You should now see a blank canvas with only the y-axis labelled. This is because we have not added any layers to the canvas yet. Figure 2.7: A blank canvas awaits our data-viz artistry So let’s add some layers to the canvas to make a graph. Here we use geom_boxplot() which creates a boxplot for us. What is a boxplot, we hear you ask? A boxplot is a graph that shows the spread of data points where the lower part of the “box” represents the bottom quartile (where 25% of the data lies), the upper part of the box represents the upper quartile (where 75% of the data lies) and the middle of the box represents the median (the middle value). The “whiskers” (vertical lines) extend to the smallest and largest values not considered outliers. Complete the code in your script so that it exactly matches the below, and then run it. Note there is a warning that 2 non-finite values have been removed. That’s just ggplot telling us ’hey, you got two NAs in here I had to take out. Did you know that?` social_media_NA %&gt;% ggplot(aes(y = time_on_social)) + #ggplot uses aesthetic (aes()) to map axes. geom_boxplot() # adds a boxplot layer to the canvas ## Warning: Removed 2 rows containing non-finite values (`stat_boxplot()`). Ok, that’s a start, but there are a few things we can do to make this graph look better. First, the x-axis is numeric, but our data is categorical (we only have one category). So we can tell ggplot() to treat the x-axis as categorical by using the scale_x_discrete() function. Update your code in your script by adding the scale_x_discrete() function. This is adding another layer to your plot. Run the code again. social_media_NA %&gt;% ggplot(aes(y = time_on_social)) + #ggplot uses aesthetic (aes()) to map axes. geom_boxplot() + #creates a boxplot scale_x_discrete() #this tells ggplot that the x-axis is categorical. ## Warning: Removed 2 rows containing non-finite values (`stat_boxplot()`). Ok, that is starting to look better. But let’s do one more thing. We can add labels to the axes using the labs() function. Update your code in your script by adding the ylab() function. Make sure your code now exactly matches what is below. Run the code again to see what you get. social_media_NA %&gt;% ggplot(aes(y = time_on_social)) + #ggplot uses aesthetic (aes()) geom_boxplot() + #creates a boxplot scale_x_discrete() + #this tells ggplot that the x-axis is categorical. ylab(&quot;Time on social media (hours)&quot;) #adds a y-axis label ## Warning: Removed 2 rows containing non-finite values (`stat_boxplot()`). There, that’s much better! Warning: We receive a warning here because ggplot() is able to recognise and remove ‘NA’ values. Be careful as not all R functions are able to do this. Question: What approximately is the median value? The lower quartile? The upper quartile? Is there another way that we could get this information in a more exact form ? Discuss this with your deskmate and your tutor. 2.11.2 Activity: More data-viz, more better - Creating a histogram in ggplot() ggplot() can be customised with so many other functions that we have shown here to make truly beautiful looking plots. We will be learning how to do this throughout the next few weeks. For now lets see if you can put some of the skills you have learned so far to good use. See if you can work out how to make a histogram of the time_on_social variable using the function geom_histogram(). Note that a histogram is a graph that shows the distribution of a single numeric variable by dividing the data into bins and counting how many data points fall into each bin. The data is plotted along the x-axis, whereas the boxplot plotted the data along the y-axis. There, no more hints! Hint: You will only need to provide an x variable this time ! OK, one more hint. Complete the below code in your script. We have been a little cheeky and have not given you the answer this time. social_media_NA %&gt;% ggplot(aes(x = )) + #ggplot uses aesthetic (aes()) to map axes. geom_histogram() + #creates a histogram labs(x = &quot;Time on social media&quot;, y = &quot;Density&quot;) + #short for &quot;labels&quot;, use to label axes and titles. theme_classic() #changes the theme of the plot to a classic theme. makes it prettier! Question: What conclusions would you draw about the shape of the data, given your histogram? Please discuss with your deskmate and tutor. 2.12 You are Free! Well done! You have completed everything you need to for this week. If you have finished in a record time please consult with your tutor about what to do next. Otherwise we will see you next lab! Also, make sure to save your script when you’re done. This is your record of what you’ve done today, and you can refer back to it later. (One more hint for the road: you will refer back to it in future labs). Figure 2.8: Students reaction to this information. "],["sec-testing-first-hypothesis.html", "Chapter 3 Testing our first hypothesis 3.1 Checking installation and loading packages 3.2 Developing our hypotheses 3.3 Visualising our data 3.4 Visualising is important 3.5 Density plots are useful (and pretty) 3.6 Descriptive statistics 3.7 Testing hypotheses manually 3.8 Testing hypothesis using a paired-sample t-test 3.9 Bonus Activity - One-sample t-tests 3.10 You are Free!", " Chapter 3 Testing our first hypothesis Today we are going to ask our first question and seek an answer from the data. We will get the data into shape so that it is in the right format for visualizing and analysing. Then we will run the analysis and learn the answer to our question. Welcome. You are now a psychologist :) 3.1 Checking installation and loading packages As usual we first always check and load in our required packages. Amend the code in your script so that it matches the code below. Then make sure it runs just fine. # Check if packages are installed, if not install. if(!require(here)) install.packages(&#39;here&#39;) #checks if a package is installed and installs it if required. if(!require(tidyverse)) install.packages(&#39;tidyverse&#39;) library(here) #loads in the specified package library(tidyverse) 3.2 Developing our hypotheses Today we are going to address one of the key questions of the study about social media use – how does mood influence active social media use? Active social media use involves interacting with content (i.e. liking posts) rather than just observing posts. There is some evidence to suggest that passive social media use is associated with lower mood in adolescents, whereas active social media use is related to positive mood Dienlin &amp; Johannes, 2020. However, a lot of the existing evidence comes from self-report, rather than measuring social media behaviour directly. To address this question, the researchers used the participants’ metadata to count how frequently they liked posts. By cross-referencing this with the mood diary kept by each participant, they were able to calculate the average number of likes per 10 minutes of use when participants were in a good mood, and when they were in a bad mood. Hopefully it’s clear by now that we will be addressing this question using the good_mood_likes and bad_mood_likes varaibles. Remember, these variables stand for the following: good_mood_likes – average number of likes made over 10 min during a good mood (from platform + diary) bad_mood_likes – as above, but during bad mood But you should know this, because you read the README.txt file already, right? :) 3.2.1 Activity - Defining our hypotheses Based on the information above, discuss and formulate hypotheses around the following: Should there be a difference in the number of likes between the mood conditions? What direction do you think this difference could be? Can you formulate an experimental hypothesis each way – i.e. good mood likes &gt; bad mood likes, and vice versa? What is the null hypothesis? Question: Discuss this with your neighbour and your tutor. Make sure you have clearly defined your hypotheses before moving forward. 3.3 Visualising our data We may have mentioned before that it’s incredibly important to visualize your data before running any statistical tests. This is because visualizing your data can help you understand the underlying distribution of the data, identify any potential outliers or anomalies, and ensure that the assumptions of the statistical test you plan to use are met. Remember, it protects against “garbage in, garbage out”! 3.3.1 Activity - Loading in the data Last lab we were very smart and saved the cleaned version of the data as a new CSV file. This is what we will be using today. We put it in the Data folder for you already. Use the Files pane to check. First step! Let’s load the dataset PSYC2001_social-media-data-cleaned.csv. To do this we use the same read.csv() function combined with here(). Do you remember how to do this? Complete the following line of code in your script. Again, we have been cheeky and have left a little bit out. But you should be able to work it out. You can also refer back to Section 2.5.1 if you need to. social_media &lt;- read.csv(file = here(???,&quot;PSYC2001_social-media-data-cleaned.csv&quot;)) #reads in CSV files Now, we did save the data ourselves last week, so we know it is clean. But just to be sure, amend your script so you can get a summary of the data using the summary() function. You can check that the -999s are no longer there. If you don’t remember how to do this, then you can check what happened in Section 2.6.1. 3.4 Visualising is important Before we conduct any kind of statistical test it is a good idea to see how it looks. This will give us an understanding about the underlying data that is driving the results of our statistical test. Warning: It is generally bad practice to go straight from the raw data to the results of a statistical test without first visualising the data. Figure 3.1: Professors’ reaction when you don’t visualise data 3.5 Density plots are useful (and pretty) One great way to look at the distribution of your variables is by using a density plot. A density plot is a smoothed version of a histogram which allows us to understand what the full distribution might look like if we had all the data in the world. More information on that is here if you are interested. In order to make plotting easy we first have to wrangle our data a bit. Remember, data analysis is 90% wrangling, 10% analysis! What we want to do here is convert our data from wideform (which is more digestible for us mere humans) into longform format (which programs like R generally like more). You can read more on that here, but to make it simple, we just need to get the key variables from our dataframe object that currently look like this: Wideform data ## id good_mood_likes bad_mood_likes ## 1 S1 22.8 46.5 ## 2 S2 46.0 48.3 ## 3 S3 50.8 46.1 ## 4 S4 29.9 29.2 ## 5 S5 37.1 52.4 ## 6 S6 26.9 20.2 And convert it into longform so that it looks like this: Longform data ## # A tibble: 6 × 3 ## id mood likes ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 S1 good_mood_likes 22.8 ## 2 S1 bad_mood_likes 46.5 ## 3 S2 good_mood_likes 46 ## 4 S2 bad_mood_likes 48.3 ## 5 S3 good_mood_likes 50.8 ## 6 S3 bad_mood_likes 46.1 As you can see, instead of having each subject’s good and bad mood likes in separate columns, we now have a single column for likes and a second column which indicates whether the likes were made in a good or bad mood. So each subject now has two rows in the dataset. This makes it much easier to plot, and to do many other things! Helpful fact You may notice that the printout of the longform data has a few extra details, compared to the wideform data. The longform data is called ‘A tibble’ which is a special type of dataframe that comes from the tidyverse package. It basically means that you used the tidyverse to make a new dataframe, and the tidyverse package turned it into a tibble for you. Tibbles have a few extra features that make them easier to work with, but they are still dataframes at their core. 3.5.1 Activity - Get back on the pipes! Its time to get back on the pipes! We get our data into longform by taking the following steps: First we use the select() function to easily choose which columns we do (or don’t) want to keep in our dataframe. Here we keep only the columns “id”, “good_mood_likes” and “bad_mood_likes”. Run the following code in your script so you can see what the select function does. Note that we are not saving this as a new object, so it will just print to the console. Handy hint: this is a great way to check what each function does! social_media %&gt;% select(&quot;id&quot;,&quot;good_mood_likes&quot;,&quot;bad_mood_likes&quot;) # choose which columns we want keep in our dataframe Bonus exercise! Try adding one more column from the dataframe to the select() function. For example, try adding the age column. Doing simple tests like this is a great way to check a function is really, really doing what you think. Once you’ve done that, remove the extra column you added so that the code matches the code above. Now that we have the columns we want to work with, we use the pivot_longer() function. This function will do all the heavy lifting turning our data from wideform to longform. Phew! This is how the using the pivot_longer function looks. social_media %&gt;% select(&quot;id&quot;,&quot;good_mood_likes&quot;,&quot;bad_mood_likes&quot;) %&gt;% # choose which columns we want keep in our dataframe pivot_longer(cols = ends_with(&quot;likes&quot;), names_to = &quot;mood&quot;, values_to = &quot;likes&quot;) #take columns ending with &quot;likes&quot; and move the column names into &quot;mood&quot; and column values into &quot;likes&quot; The pivot_longer() function takes three important arguments. The cols argument tells R which columns contain the key variables that we need to turn into longform. Here we use the ends_with() function to tell R to take all columns which end with “likes”, nifty! The names_to argument tells R what to call the new column which will contain the names of the columns we are pivoting (i.e good or bad mood). Here we call this new column “mood”, as this is a good title for a column that will list whether the data were recorded when someone was either in a “good mood” or a “bad mood”. The values_to argument tells R what to call the new column which will contain the values from the columns we are pivoting (i.e the rate of likes). Here we call this new column “likes”, because, erm, it contains the rate of likes. Highlight and run this code in your script to see the work of pivot_longer! Now, very important, save the results of your nifty coding work to a new dataframe so that you can do impressive things to the results, like making density plots! Amend the above code in your script so that your dataframe is saved to an object called social_media_likes. Then run the code to create the new dataframe. Let’s make sure that this data still looks okay by using the head() function. Complete the code in your script so that it looks exactly like below, and run it to check the result is the same as you see here. head(social_media_likes) ## # A tibble: 6 × 3 ## id mood likes ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 S1 good_mood_likes 22.8 ## 2 S1 bad_mood_likes 46.5 ## 3 S2 good_mood_likes 46 ## 4 S2 bad_mood_likes 48.3 ## 5 S3 good_mood_likes 50.8 ## 6 S3 bad_mood_likes 46.1 Et voila! 3.5.2 Activity - start plotting Now, we can have done the wrangling (90%), we can get onto visualising and analysis! We get a density plot in R by using the geom_density function with ggplot(). To do this, we need to add a bit more information to the ggplot() function, compared to when we created a boxplot in Section 2.11.1. To make a density plot we need to tell it what variable we want to plot on the x-axis (likes), and we also want to tell it to use different density plots with different colours for the different moods. We tell ggplot() these things by calling the aes() function. You can think of aes() as setting the aesthetics of the plot. We tell aes() that we want to group the data by mood, and to fill in the density plots with different colours, depending on which mood is being plotted. Run the below code in your script to see what happens. social_media_likes %&gt;% ggplot(aes(x = likes, group = mood, fill = mood)) + # set the aesthetics that will be worked # with on the canvas geom_density() # use the data to draw a density plot So…this is OK. But some things are left to be desired. It would be nice if good_mood_likes didn’t occlude bad_mood_likes, because we want to see how both distributions look. Amend your code so that the density plots are semi-transparent. You can do this by adding an alpha argument inside the geom_density() function. You can think of alpha as a value that tells you how transparent something should be. Set alpha = 0.5 to make the plots 50% transparent. Make your code match what you see below and run it to get the sweet results. social_media_likes %&gt;% ggplot(aes(x = likes, group = mood, fill = mood)) + # set the aesthetics that will be worked # with on the canvas geom_density(alpha=0.5) # use the data to draw a density plot and make it 50% transparent Ahhh, that’s better! Then the last step, if you are striving for data viz beauty, is to add the classic theme (or another, if that’s your jam) to your code. For example: social_media_likes %&gt;% ggplot(aes(x = likes, group = mood, fill = mood)) + geom_density(alpha=0.5) + theme_classic() #themes can be provided to ggplot which give it a bunch of aesthetics to change. One of these is theme_classic 3.5.3 Activity - So you’ve visualised your data, now what? Great, we’ve visualised the data! So, now what? I hear you cry? We visualised the data so we could check the following things before running our statistical test: - are the distributions of likes in each mood roughly normal? - are there any obvious outliers that might affect the results of our statistical test? What do you think? You can discuss this with your neighbour and tutor. 3.6 Descriptive statistics Before we can move onto conducting t-tests, the next step is to understand the descriptive statistics. For the data we are looking at the most relevant descriptive statistics are the mean and standard deviation. This is because we want to conduct a t-test to compare the average likes in different moods. The t-test asks if the difference between the means is larger than we would expect by chance, given the variability in the data (i.e. the standard deviation). That’s why we need to know the mean and standard deviation of likes in each mood. Tidyverse to the rescue! We can easily get this information in R by using the summarise() function. The summarise function will take a dataframe and calculate summary statistics for it, and we get to define what summary statistics we want. The power! Because we want to know the mean and standard deviation of likes in each mood, we need to use the group_by() function to tell R to split the data by mood first. 3.6.1 Activity - get descriptive! Amend the following code in your script so that it matches what you see below. Then run it to get the mean and standard deviation of likes in each mood. social_media_likes %&gt;% group_by(mood) %&gt;% #split the data by mood summarise(mean = mean(likes), sd = sd(likes)) #calculate the mean number of likes ## # A tibble: 2 × 3 ## mood mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 bad_mood_likes 49.8 17.2 ## 2 good_mood_likes 43.0 16.1 We can also save this as a new dataframe if we want to use it later. Amend your code so that the results are saved to a new dataframe object called social_media_descriptives. Then run the code to create the new dataframe. Question: What are the mean number of likes in each different mood? What is the standard deviation? How do they compare to what you expected when you made your hypotheses? 3.7 Testing hypotheses manually Now that we have had a look at the structure and descriptives statistics of our data we can have a go at using a t-test to compare the number of likes participants made in a good and bad mood. We could of course do this manually, by hand (as we have in the statistics tutorials). We have shown this below using the first 10 values for good and bad mood likes. Figure 3.2: t-test table Thankfully, we have long since past the stone (pen) age so it is no longer necessary to do this by hand. We can get computers to do this for us! Figure 3.3: Handwritten statistiscs be like 3.8 Testing hypothesis using a paired-sample t-test We can very easily calculate a t-test with R using the t.test() function which comes as part of baseR. Please first have a look at the help for this function using the ? syntax, much as you did in Section 1.5. We recommend you type your request for t.test help info directly into the console. You should now see some helpful in the Help pane. Figure 3.4: Handy t-test help We can see that t.test() takes different arguments which are important for the way it handles the data. What values you provide to these arguments is dependent on what kind of test you want to conduct. 3.8.1 Activity - Conducting a paired t-test We are going to go through the arguments we need to perform a paired sample t-test. We can see from the help info that we should input a set of data values to an argument called x and another set of data values to an argument called y. You can think of x and y as stand-in names for the two variables we want to compare, which are good_mood_likes and bad_mood_likes. Now the t.test function is from base R, and now you get to meet one of the peculiarities of base R. The x and y arguments expect your data to be in wideform format –But we did all that work getting it into longform, I hear you cry– Yes, we did. But remember, that allowed us to easily compute descriptive statistics and visualise the data. Luckily for us, we also have the original wideform data saved in the social_media dataframe. So we will use that to compute our t-test. To do that, we need to know about a magical operator in R which is $. The $ operator allows us to access specific columns in a dataframe. For example, if we wanted to access the good_mood_likes column in the social_media dataframe, we would use social_media$good_mood_likes. This tells R to look in the social_media dataframe and get the stuff that lives in the column called good_mood_likes. Complete the line in your script so that it matches below, and then run it to see what happens. social_media$good_mood_likes #access the good_mood_likes column in the social_media dataframe You should see all the numbers from the good_mood_likes column, printed to the dataframe. That’s exactly what the t.test() function needs to see to do its work. Complete the code in your script so that it matches what you see below. But don’t run it yet! There are some more things we need to tell t.test() before we can get it to do what we want. t.test(x=social_media$good_mood_likes, #the x argument gets the good_mood_likes data y=social_media$bad_mood_likes) #the y argument gets the bad_mood_likes data Now there is one more argument that we super care about setting when performing a t test. This is the paired argument. The paired argument tells R whether the two sets of data we are comparing are dependent (e.g. from the same people) or independent (e.g. from different people). We refer to dependent observations as “paired”. Here, we know that the good and bad mood likes are from the same people, so we need to set paired = TRUE. If we were comparing likes from two different groups of people, we would set paired = FALSE. Update the code in your script so that it exactly matches the below. Run it and check the output is the same as what we have here. t.test(x=social_media$good_mood_likes, #the x argument gets the good_mood_likes data y=social_media$bad_mood_likes, #the y argument gets the bad_mood_likes data paired = TRUE) #tell R that the data are paired (i.e. from the same people) ## ## Paired t-test ## ## data: social_media$good_mood_likes and social_media$bad_mood_likes ## t = -3.336, df = 59, p-value = 0.001474 ## alternative hypothesis: true mean difference is not equal to 0 ## 95 percent confidence interval: ## -10.881375 -2.721958 ## sample estimates: ## mean difference ## -6.801667 Now we have some answers! Use your new found knowledge of t-tests to interpret the output. What does it tell you? Does it refute the null hypothesis? Does it support what you thought? Discuss the output with your tutor and neighbour. 3.9 Bonus Activity - One-sample t-tests If you have cracked all the activities above, well done, you are coding like a fiend. Time for bonus knowledge. Now that we have the output of a paired t-test we can compare it to a one sample t-test. The results of both of these tests should be identical (this has been covered in the lectures). For those that haven’t attended the lectures, a) attend the lectures because if not you will miss out on so much more knowledge, and b) this is because a paired t-test is basically a one-sample t-test of matched difference scores (more on that here) Let’s conduct a one-sample t-test of the difference scores between good and bad mood likes. First you will need to use the mutate() function on the original social_media dataframe to create a difference score column. Run this code in your script to see what happens. This will show you the mutate() function in action. social_media %&gt;% mutate(likes_diff = good_mood_likes - bad_mood_likes) #create a new column which is the difference between # good and bad mood likes ## X id age time_on_social urban good_mood_likes bad_mood_likes followers polit_informed ## 1 1 S1 15.2 3.06 1 22.8 46.5 173.3 2.3 ## 2 2 S2 16.0 2.18 1 46.0 48.3 144.3 1.6 ## 3 3 S3 16.8 1.92 1 50.8 46.1 76.5 1.9 ## 4 4 S4 15.6 2.61 1 29.9 29.2 171.7 1.6 ## 5 5 S5 17.1 3.24 1 37.1 52.4 109.5 2.0 ## 6 6 S6 15.7 2.44 1 26.9 20.2 157.5 2.4 ## polit_campaign polit_activism likes_diff ## 1 3.2 3.6 -23.7 ## 2 2.2 2.6 -2.3 ## 3 2.7 3.0 4.7 ## 4 2.3 2.6 0.7 ## 5 2.9 3.3 -15.3 ## 6 3.4 3.9 6.7 Now, we’re going to need to save that dataframe to an object called social_media_diff, so that we can use it in the t.test() function. Update the code you just ran so that it starts with social_media_diff &lt;- and run it to save the dataframe. Now that we have correctly calculated and saved our difference score we can use the t.test() function to perform our one-sample t.test. Run this code in your script, and compare the output to the output of the paired t-test you did earlier. Are they the same? Question: Compare the output of the one-sample t-test and the paired t-test. Are they the same? t.test(x=social_media_diff$likes_diff) # putting in only an x argument makes this a one-sample t-test ## ## One Sample t-test ## ## data: social_media_diff$likes_diff ## t = -3.336, df = 59, p-value = 0.001474 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -10.881375 -2.721958 ## sample estimates: ## mean of x ## -6.801667 Ahhhh, its so beautiful when you get consistent results! 3.10 You are Free! Well done you have finished for this week! Once you finish, please confirm with your tutor that you understand all the things. Figure 3.5: Students leaving evil statistics classes "],["testing-for-differences-between-groups.html", "Chapter 4 Testing for differences between groups 4.1 Checking installation and loading packages 4.2 Wrangling our data 4.3 Visualising our data 4.4 Next step: descriptive statistics 4.5 Independent samples t-test 4.6 Writing up results and conclusions 4.7 Bonus - Visualising group differences 4.8 You are Free!", " Chapter 4 Testing for differences between groups This week we will be learning how to conduct an independent samples t-test. This is a statistical test that allows us to compare the means of two independent groups on a continuous outcome variable. According to the 90/10 theorem, we will spend 90% of our time wrangling and visualising our data, and 10% of our time actually conducting the t-test. 4.1 Checking installation and loading packages As usual we first always check and load in our required packages. # Check if packages are installed, if not install. if(!require(here)) install.packages(&#39;here&#39;) #checks if a package is installed and installs it if required. if(!require(tidyverse)) install.packages(&#39;tidyverse&#39;) library(here) #loads in the specified package library(tidyverse) In Chapter 3, we performed an analysis to learn how mood impacts active social media behaviour. However, that is not the only factor that influences social media use. For example, Sapienza et al (2023) found that people in rural areas are more likely to use their smartphone for social media and gaming, whereas urban dwellers are more likely to use their phone for navigation and business. However, we do not know if people living in urban and rural areas engage with social media differently, regardless of how long they spend on their chosen platforms. Today we will address this question using the urban, good_mood_likes, bad_mood_likes, and followers variables. Remember, these variables stand for the following: urban – urban (1) or rural (2) area (based on postcode density) good_mood_likes – average number of likes made over 10 min during a good mood (from platform + diary) bad_mood_likes – as above, but during bad mood followers – average number of followers across platforms 4.1.1 Activity - Formulate your research question What do you think? Will urban and rural dwellers engage differently with social media? Will there be a difference in the number of likes made by people living in urban vs rural areas? Or in the number of followers people have in urban vs rural areas? Question: What are the null hypotheses for your research questions (you should have one for ‘likes’ and one for ‘followers’? Now, what predictions would you make about differences? Extra info: We are going to average over the effect of mood, so we do not need to include mood in our predictions about likes. 4.1.2 Activity - Load in data and check it Today we will be averaging across mood to get the number of likes for urban and rural dwellers. This means we first need to create a new variable called likes which is the average of the likes in a good and bad mood. We first load in ourPSYC2001_social-media-data-cleaned.csv dataset. Copy and paste this code into your script and run it to load in the data. social_media &lt;- read.csv(file = here(&quot;Data&quot;,&quot;PSYC2001_social-media-data-cleaned.csv&quot;)) #reads in CSV files Lets double check its the data we think it is by using the head() function. See that we’ve added in an argument to say we want to see the first 10 lines of the data. Amend your code in your script to look at the number of rows your very own eyes want to see. head(social_media, 10) # you can even say how many lines you want to see! Try changing the number, and see what happens. ## X id age time_on_social urban good_mood_likes bad_mood_likes followers ## 1 1 S1 15.2 3.06 1 22.8 46.5 173.3 ## 2 2 S2 16.0 2.18 1 46.0 48.3 144.3 ## 3 3 S3 16.8 1.92 1 50.8 46.1 76.5 ## 4 4 S4 15.6 2.61 1 29.9 29.2 171.7 ## 5 5 S5 17.1 3.24 1 37.1 52.4 109.5 ## 6 6 S6 15.7 2.44 1 26.9 20.2 157.5 ## 7 7 S7 19.7 1.46 1 14.8 35.1 166.9 ## 8 8 S8 18.6 1.52 1 26.0 35.8 109.6 ## 9 9 S9 19.6 1.92 1 6.5 12.2 253.4 ## 10 10 S10 15.5 2.10 1 45.7 32.8 77.2 ## polit_informed polit_campaign polit_activism ## 1 2.3 3.2 3.6 ## 2 1.6 2.2 2.6 ## 3 1.9 2.7 3.0 ## 4 1.6 2.3 2.6 ## 5 2.0 2.9 3.3 ## 6 2.4 3.4 3.9 ## 7 1.7 2.4 2.7 ## 8 1.6 2.2 2.6 ## 9 1.5 2.1 2.4 ## 10 2.2 3.1 3.5 4.2 Wrangling our data There are a couple of things we need to do to get our data into shape. The first is to create our new variable likes which is the average of good_mood_likes and bad_mood_likes. The second is to define the urban factor correctly. More on that to come! 4.2.1 Activity - Creating a new likes variable We need to create a new variable called likes which is the average of good_mood_likes and bad_mood_likes. To do this, we are going to use the mutate() function from the tidyverse package. You can think of using mutate() as a way to create a new column in your dataframe, using information from other columns. To use mutate() we need to use the pipe operator %&gt;% which we also used in Section 3.5.1. The pipe operator takes the output of one function and uses it as the input for the next function. This is very useful when we want to do multiple things to a dataframe in a single line of code. We are going to use the pipe operator to take the social_media dataframe and then use mutate() to create our new variable likes. Because we want the average likes, we will add good_mood_likes and bad_mood_likes together and then divide by 2. Run the following line of code in your script to see the output. social_media_likes &lt;- social_media %&gt;% mutate(likes =(bad_mood_likes + good_mood_likes)/2 ) # creates a new variable called likes which is the average of bad_mood_likes and good_mood_likes ## X id age time_on_social urban good_mood_likes bad_mood_likes followers ## 1 1 S1 15.2 3.06 1 22.8 46.5 173.3 ## 2 2 S2 16.0 2.18 1 46.0 48.3 144.3 ## 3 3 S3 16.8 1.92 1 50.8 46.1 76.5 ## 4 4 S4 15.6 2.61 1 29.9 29.2 171.7 ## 5 5 S5 17.1 3.24 1 37.1 52.4 109.5 ## 6 6 S6 15.7 2.44 1 26.9 20.2 157.5 ## 7 7 S7 19.7 1.46 1 14.8 35.1 166.9 ## 8 8 S8 18.6 1.52 1 26.0 35.8 109.6 ## 9 9 S9 19.6 1.92 1 6.5 12.2 253.4 ## 10 10 S10 15.5 2.10 1 45.7 32.8 77.2 ## polit_informed polit_campaign polit_activism likes ## 1 2.3 3.2 3.6 34.65 ## 2 1.6 2.2 2.6 47.15 ## 3 1.9 2.7 3.0 48.45 ## 4 1.6 2.3 2.6 29.55 ## 5 2.0 2.9 3.3 44.75 ## 6 2.4 3.4 3.9 23.55 ## 7 1.7 2.4 2.7 24.95 ## 8 1.6 2.2 2.6 30.90 ## 9 1.5 2.1 2.4 9.35 ## 10 2.2 3.1 3.5 39.25 You can see that mutate() has created an extra column called likes. You can manually check that the first couple of values are correct, by adding the good_mood_likes and bad_mood_likes values together and dividing by 2. Tip: Manually checking that a function has done what you think it should is a good habit to get into. It will help you catch mistakes early on. Looking at the dataframe above, we can see that the first value for good_mood_likes is 22.8 and the first value for bad_mood_likes is 46.5. Lets add them together and divide by 2, to check the answer is the same as the first value for likes, which is 34.65. Type the below into your console and check you get the same answer: (22.8 + 46.5) / 2 ## [1] 34.65 Woohoo! Now, this dataframe has all we need for our analysis, and a lot more! Let’s make things simpler for ourselves by only keeping the variables we need. We can do this by once again using the pipe operator, along with the select() function. Update the code in your script so that it looks like this: social_media_likes &lt;- social_media %&gt;% mutate(likes =(bad_mood_likes + good_mood_likes)/2 ) %&gt;% # creates a new variable called likes which is the average of bad_mood_likes and good_mood_likes select(id, urban, likes, followers) #selects only the specified columns from the dataframe Check that you got what you want by using the head() function again. 4.2.2 Activity - Defining factors Now that we have this dataframe object it is important to check that R can understand the data properly. Lets use the str() function that we learned about in Section 2.6.1 to examine what R thinks about each column. Complete the code in your script and run it, to make sure you get the same results. str(social_media_likes) #provides a summary of the data structure. ## &#39;data.frame&#39;: 60 obs. of 4 variables: ## $ id : chr &quot;S1&quot; &quot;S2&quot; &quot;S3&quot; &quot;S4&quot; ... ## $ urban : int 1 1 1 1 1 1 1 1 1 1 ... ## $ likes : num 34.6 47.1 48.5 29.5 44.8 ... ## $ followers: num 173.3 144.3 76.5 171.7 109.5 ... What have we learned? We can see that R thinks that urban contains integers (int), i.e. R thinks that urban is a column of real numbers containing 1s and 2s. But urban is not a numeric variable, it is actually a factor (categorical variable). If you remember from the README.txt file (which you read already, right? :)), 1 stands for urban and 2 stands for rural. We need to tell R this, so that it can understand the data properly. To do this, we can use the as_factor() function, which converts a variable to a factor. We also need to tell R that 1 means urban and 2 means rural. We can do this using the factor() function within mutate(). The mutate() function is coming in handy today! social_media_likes &lt;- social_media_likes %&gt;% mutate(urban = factor(urban, levels=c(1,2), labels=c(&#39;urban&#39;, &#39;rural&#39;))) #changes the urban variable to a factor with levels urban and rural Now we want to test that this code did what we wanted it to do. Use the str() function again to check that urban is now a factor. str(social_media_likes) ## &#39;data.frame&#39;: 60 obs. of 4 variables: ## $ id : chr &quot;S1&quot; &quot;S2&quot; &quot;S3&quot; &quot;S4&quot; ... ## $ urban : Factor w/ 2 levels &quot;urban&quot;,&quot;rural&quot;: 1 1 1 1 1 1 1 1 1 1 ... ## $ likes : num 34.6 47.1 48.5 29.5 44.8 ... ## $ followers: num 173.3 144.3 76.5 171.7 109.5 ... Excellent! We can see that R now thinks that urban is a factor with 2 levels: urban and rural. Our data is now in a format that we should be able to easily visualise it and conduct our statistical tests. 90% done :) Figure 4.1: What it feels like teaching this section 4.3 Visualising our data If you remember from Section 3.5.3, we learned that we need to visualise our data to check if the distributions look roughly normal, and to check there are no obvious outliers or strange values that will impact our analysis. Today, we are going to examine our variables using histograms. Just as we did in Section 2.11.2. We have copied the code from Section 2.11.2 below, and have added a few options into the geom_histogram() function so that you can get a nice looking histogram. This code is also in your script. 4.3.1 Adapting our previous code to make new histograms Your challenge, should you choose to accept it*, is to change the code in your script so that you instead make a histogram for likes using the social_media_likes dataframe. Also remember to adjust the axis labels! *You have to accept it. Determinism beats free will. ## health warning. This is old code that needs to be adapted for current purposes! social_media_NA %&gt;% ggplot(aes(x = )) + #ggplot uses aesthetic (aes()) to map axes. geom_histogram(binwidth=10, col=&quot;black&quot;, fill=&quot;seagreen&quot;) + #creates a histogram with blue fill, black borders, and a binwidth of 10 labs(x = &quot;Time on social media&quot;, y = &quot;Density&quot;) + #short for &quot;labels&quot;, use to label the axes. theme_classic() #changes the theme of the plot to a classic theme. makes it prettier! You should get a histogram that looks something like this: What would you say about this data, now you have looked at the histogram? Does it look normally distributed? Are there any outliers? Now, can you make a density plot for followers? Copy and paste the code you used to make the histogram for likes and make the teeny changes required. Go on, you are a coder, and you are strong. Question: Does followers look normally distributed to you? Why might the data be shaped how it is? Indeed, the followers variable looks different to the likes variable. This is not too surprising. A fewer number of people in the sample have a huge number of followers, and the rest have a more modest number. Just like in real life. Random sampling works! Ahhh, science. Because the followers variable is not normally distributed, we will need to be a bit cautious when interpreting the results of our t-test later on. But we can still proceed, as the t-test is quite robust to violations of normality. You would just make sure to mention this in your write-up, so that your readers also know. 4.4 Next step: descriptive statistics Now that we know what shape our data is in, and when we should exercise caution, we can move on to generating some descriptive statistics of our key variables. In Section 3.6.1 we learned how to summarise our data to get descriptive statistics. Now you’ll get to see some more of the joy of coding - once you have written a bit of code that does something you need, its very easy to adapt it to do something else you need. Here is the code we wrote last week to get descriptive statistics of the rate of likes, grouped by mood: social_media_likes %&gt;% group_by(mood) %&gt;% #split the data by mood summarise(mean = mean(likes), sd = sd(likes)) #calculate the mean number of likes We want to adapt this code to get the mean and standard deviation for likes and followers, this time grouping by urban. You will find the below code in your script. Complete it to get the descriptive statistics you need. social_media_descriptives &lt;- social_media_likes %&gt;% # save to new object called social_media_descriptives group_by() %&gt;% # group the data by urban summarise( mean_followers = mean(followers), # calculate the mean number of followers for urban and rural groups separately mean_likes = mean(likes), sd_followers = sd(), sd_likes = sd() ) social_media_descriptives Check that your output for social_media_descriptives looks like this: ## # A tibble: 2 × 5 ## urban mean_followers mean_likes sd_followers sd_likes ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 urban 144. 40.8 62.0 14.5 ## 2 rural 106. 52.1 40.9 12.7 Look at the mean values you have generated for urban and rural dwellers. Do they make sense to you? Do they fit with your predictions from earlier? 4.5 Independent samples t-test Now we are down to the very last few percents of our 10% of analysis efforts. Let’s perform an independent samples t-test to see if there are statistically significant differences between urban and rural dwellers in terms of their likes and followers. 4.5.1 Activity - Performing an independent samples t-test In Section 3.8.1 we learned how to conduct a paired samples t-test. To do this, we had to deal with niggly base R demands and use the wideform data instead of our carefully wrangled longform data. Fortunately, the t.test() function is a bit more forgiving when it comes to independent samples t-tests, and we can use our longform data combined with a nifty thing that base R knows about, which is formulas. Huzzah. This is how we use the formula method in t.test(). The syntax is t.test(outcome ~ group, data = dataframe). So, for our data, we want to test if likes differ by urban, using the social_media_likes dataframe. Note that you don’t need to set the paired argument to FALSE, as the t.test() function assumes this whenever you use the formula method. So never use the formula method for a paired samples t-test. That would be a disaster. Run the below line of code in your script, to check you get the same output. t.test(likes~urban, data=social_media_likes) # conducts an independent samples t-test to see if likes differ by urban/rural status ## ## Welch Two Sample t-test ## ## data: likes by urban ## t = -3.2184, df = 56.996, p-value = 0.002129 ## alternative hypothesis: true difference in means between group urban and group rural is not equal to 0 ## 95 percent confidence interval: ## -18.338983 -4.271017 ## sample estimates: ## mean in group urban mean in group rural ## 40.78833 52.09333 Question: Discuss the output of this independent t-test, what does it tell you about the differences between urban and rural dwellers and how they actively use social media? Is it what you expected when you formulated your hypothesis? Now complete the following line of code in your own script, to test if followers differ by urban. t.test(???, data=social_media_likes) # conducts an independent samples t-test to see if followers differ by urban/rural status Check your output with what you see below to make sure you got it right. Also, make sure to interpret what the output is telling you! ## ## Welch Two Sample t-test ## ## data: followers by urban ## t = 2.8182, df = 50.234, p-value = 0.00689 ## alternative hypothesis: true difference in means between group urban and group rural is not equal to 0 ## 95 percent confidence interval: ## 10.98893 65.49107 ## sample estimates: ## mean in group urban mean in group rural ## 143.8767 105.6367 Figure 4.2: Every PSYC2001 midterm 4.6 Writing up results and conclusions This is how we would write up the results of an independent samples t-test. Results: An independent samples t-test indicated that the number of likes was greater for rural (M = 52.1 , SD = 12.7) compared to urban dwellers (M = 40.8 , SD = 14.5) and this difference was statistically significant (t(58) = 3.22, p = 0.002). Conversely, the number of followers was greater for urban (Mean = 143.9, SD = 62.0) than for urban dwellers (M = 105.6, SD = 40.9) which was statistically significant (t(58) = 2.82, p = 0.007). 4.7 Bonus - Visualising group differences If you have made it this far with time to spare, then kudos. Here are some extra skills that will be very helpful when you need to present results relating to group differences. Which you might need to do in a certain upcoming assignment. Earlier, we looked at the overall histograms for likes and followers. But when presenting our findings in a results section, what the reader really wants to see is how the groups differ from each other. One effective way to do this is to make a grouped boxplot. See here for more details on boxplots. Let’s make a boxplot together, showing the likes data split by urban and rural groups. We are going to use a couple of new functions here (geom_boxplot(), scale_fill_manual()), which we explain in the comments below. social_media_likes %&gt;% ggplot(aes(y = likes, group=urban, fill = urban, x = urban)) + # here we are telling ggplot that we will be putting likes # on the y axis, that we will fill in our boxplots with colour using the urban factor, and that urban will go on the x-axis geom_boxplot() + # this function creates a boxplot labs(x = &quot;Living Area&quot;, y = &quot;Average Rate of Likes&quot;) + # here we use labs() to label our axes. scale_fill_manual(values = c(rural = &quot;plum&quot;, urban = &quot;cyan2&quot;)) + #manually define the filled in colours of specific parts of a graph - see here for more R colours: https://r-graph-gallery.com/42-colors-names.html theme_classic() Now we return to another critical part of coding. Copying and pasting what you have, and changing just a few bits. Now, can you change the code above to make a boxplot for followers instead of likes? You will need to change what you give for the y argument in aes(), and the y-axis label. You can also change the colours if you want to. Copy and paste the original code in your script and make your changes. You should get something that looks like this: Last, we often want to save our figures as image files, so that we can include them in reports or presentations. This is very easy to do using the ggsave() function. First, you should save the plot you want to save to an object. You can do this by amending your boxplot code so that the output saves to an object, such as you see below. likes_bp &lt;- social_media_likes %&gt;% ggplot(aes(y = likes, group=urban, fill = urban, x = urban)) + geom_boxplot() + # this function creates a boxplot labs(x = &quot;Living Area&quot;, y = &quot;Average Rate of Likes&quot;) + # here we use labs() to label our axes. scale_fill_manual(values = c(rural = &quot;plum&quot;, urban = &quot;cyan2&quot;)) + theme_classic() Amend your code now to save your followers boxplot to an object called followers_bp. Run the code and check the object appears in your Environment pane. Then, you can use the ggsave() function to save the plot to a file. The syntax is ggsave(\"filename.png\", plot = plot_name). You can change the file extension to save in different formats (e.g., .jpg, .pdf). We want to be extra smart and save the file to our Output folder, so we will use the here() function to specify the path. Copy and paste this code to your script, and change it to save your followers_bp plot instead of the likes_bp plot. ggsave(here(&quot;Output&quot;, &quot;likes_boxplot.png&quot;), plot = likes_bp) # saves the likes boxplot to the Output folder as a PNG file 4.8 You are Free! Well done! This computing tutorial is now over. Make sure to thank your tutor for another amazing class full of wonderful statistics and learning! Figure 4.3: Everyone loves statistics ? "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
